{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "928df22e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "tqdm.pandas()\n",
    "import numpy as np\n",
    "\n",
    "from utils import clean_dataset_basedOn_media\n",
    "from utils import cluster_by_month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f56333f",
   "metadata": {},
   "source": [
    "We can use the coherence score in topic modeling to measure how interpretable the topics are to humans. In this case, topics are represented as the top N words with the highest probability of belonging to that particular topic. Briefly, the coherence score measures how similar these words are to each other.\n",
    "#### CV Coherence Score\n",
    "\n",
    "One of the most popular coherence metrics is called CV. It creates content vectors of words using their co-occurences and, after that, calculates the score using normalized pointwise mutual information (NPMI) and the cosine similarity. This metric is popular because it's the default metric in the Gensim topic coherence pipeline module, but it has some issues.\n",
    "\n",
    "https://github.com/dice-group/Palmetto/issues/13#issuecomment-371553052\n",
    "\n",
    "#### UMass Coherence Score\n",
    "\n",
    "It calculates how often two words, $w_i$ and $w_j$ appear together in the corpus and it's defined as:\n",
    "\n",
    "<img src=\"https://www.baeldung.com/wp-content/ql-cache/quicklatex.com-88c21c21c59dc5699d130bfeca00a5c7_l3.svg\" />\n",
    "\n",
    "where $D(w_i, w_j)$ indicates hwo many times words $w_i$ and $w_j$ appear together in documents, and $D(w_i)$ is how many time word $w_i$ appeared alone. The greater the number, the better is coherence score. Also, this measure isn't symmetric, which means that $C_UMass (w_i, w_j)$ in not equal to $C_UMass (w_j, w_i)$. We calculate the global coherence of the topic as the average pairwise coherence scores on the top $N$ words which describe the topic.\n",
    "\n",
    "#### UCI Coherence Score\n",
    "This coherence score is based on sliding windows and the pointwise mutual information of all word pair using top $N$ words by occurence. Instead of calculating how often two words appear in the document, we calculate the word co-occurence using a sliding window. It means that if our sliding window has a size of 10, for one particular word $w_i$, we observe only 10 words before and after the word $w_i$.\n",
    "\n",
    "Therefore, if both words $w_{i}$ and $w_{j}$ appeared in the document but they’re not together in one sliding window, we don’t count as they appeared together. Similarly, as for the UMass score, we define the UCI coherence between words $w_{i}$ and $w_{j}$ as\n",
    "\n",
    "<img src =\"https://www.baeldung.com/wp-content/ql-cache/quicklatex.com-02e9dd099b3bc039c06661397ddc3d0d_l3.svg\"/>\n",
    "\n",
    "where $P(w)$ is probability of seeing word w in the sliding window and $P(w_{i}, w_{j})$ is probability of appearing words $w_{i}$ and $w_{j}$ together in the sliding window. In the original paper, those probabilities were estimated from the entire corpus of over two million English Wikipedia articles using a 10-words sliding window. We calculate the global coherence of the topic in the same way as for the UMass coherence.\n",
    "\n",
    "#### Word2vec Coherence Score\n",
    "\n",
    "This will introduce the semantic of the words in our score. Basically, we want to measure our coherence based on two criteria:\n",
    "1. Intra-topic similarity - the similarity of words in the same topic.\n",
    "2. Inter-topic similarity - the similarity of words across different topics.\n",
    "\n",
    "The idea is pretty simple. We want to maximize intra-topic and minimize inter-topic similarity. Also, by similarity, we imply the cosine similarity between words represented by word2vec embedding.\n",
    "\n",
    "Following that, we compute intra-topic similarity per topic as an average similarity between every possible pair of top $N$ words in that topic. Consequently, we compute the inter-topic similarity between two topics as an average similarity between top $N$ words from these topics. \n",
    "\n",
    "Finally, the word2vec coherence score between two topics, $t_i$ and $t_j$, is calculated as \n",
    "\n",
    "<img src=\"https://www.baeldung.com/wp-content/ql-cache/quicklatex.com-0912ea7a1eda042b202bff1cbbd68ee2_l3.svg\" />\n",
    "\n",
    "### Choosing the best coherence score\n",
    "\n",
    "There is no one way to determine whether the coherence score is good or bad. The score and its value depends on the data that it's calculated from. For instance, in one case, the score of 0.5 might be good enough but in another case not acceptable. The only rule is that we want to **maximize** the score.\n",
    "\n",
    "Usually, the coherence score will increase with the number of topics . This increase will become smaller as the number of topics get higher. The trade-off between the number of topics and coherence score can be achieved using the so-called elbow technique. The method implies plotting coherence score as a function of number of topics. We use the elbow of the curve to select the number of topics.\n",
    "\n",
    "\n",
    "The idea behind this method is that we want to choose a point after which the diminishing increase of coherence score is no longer worth the additional increase of number of topics.\n",
    "\n",
    "Also, the coherence score depends on the LDA hyperparameters, such as $\\alpha , \\beta$ and $K$. Because of that, we can use any machine learning hyperparameter tuning technique.\n",
    "\n",
    "After all, it's important to manually validate results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0a29a4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date               False\n",
       "media_outlet       False\n",
       "url                False\n",
       "title              False\n",
       "text               False\n",
       "content            False\n",
       "comuna              True\n",
       "date_clustering    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../data/loslagos-comunas.csv\")\n",
    "df = cluster_by_month(clean_dataset_basedOn_media(df))\n",
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af70e054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2022-03    4617\n",
       "2021-12    4492\n",
       "2021-10    4370\n",
       "2021-11    4326\n",
       "2022-01    4182\n",
       "2022-02    3950\n",
       "2022-04    3384\n",
       "Name: date_clustering, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.date_clustering.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dfa3d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos las etiquetas del value_counts \n",
    "months = df.date_clustering.value_counts().index.tolist()\n",
    "\n",
    "# se hará un análisis del primer mes\n",
    "import datetime\n",
    "dates = [datetime.datetime.strptime(ts, \"%Y-%m\") for ts in months]\n",
    "dates.sort()\n",
    "sorteddates = [datetime.datetime.strftime(ts, \"%Y-%m\") for ts in dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a276786",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = df[df.date_clustering == sorteddates[0]]\n",
    "docs = selected.content.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50c1ded",
   "metadata": {},
   "source": [
    "# [gensim coherence score](https://radimrehurek.com/gensim/models/coherencemodel.html)\n",
    "\n",
    "The four stage pipeline is basically:\n",
    "\n",
    "- Segmentation\n",
    "\n",
    "- Probability Estimation\n",
    "\n",
    "- Confirmation Measure\n",
    "\n",
    "- Aggregation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acb75c4a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5c4223e391f4323b4f24cc10ff9c37c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/137 [00:02<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-29 18:20:29,253 - BERTopic - Transformed documents to Embeddings\n",
      "2022-09-29 18:21:06,949 - BERTopic - Reduced dimensionality\n",
      "2022-09-29 18:21:08,748 - BERTopic - Clustered reduced embeddings\n"
     ]
    }
   ],
   "source": [
    "from bertopic import BERTopic\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "topic_model = BERTopic(verbose=True,\n",
    "                       calculate_probabilities=True,\n",
    "                       n_gram_range=(1, 3),\n",
    "                       language=\"spanish\")\n",
    "topics, _ = topic_model.fit_transform(docs)\n",
    "\n",
    "# Preprocess Documents\n",
    "documents = pd.DataFrame({\"Document\": docs,\n",
    "                          \"ID\": range(len(docs)),\n",
    "                          \"Topic\": topics})\n",
    "documents_per_topic = documents.groupby(['Topic'], as_index=False).agg({'Document': ' '.join})\n",
    "cleaned_docs = topic_model._preprocess_text(documents_per_topic.Document.values)\n",
    "\n",
    "# Extract vectorizer and analyzer from BERTopic\n",
    "vectorizer = topic_model.vectorizer_model\n",
    "analyzer = vectorizer.build_analyzer()\n",
    "\n",
    "# Extract features for Topic Coherence evaluation\n",
    "words = vectorizer.get_feature_names()\n",
    "tokens = [analyzer(doc) for doc in cleaned_docs]\n",
    "dictionary = corpora.Dictionary(tokens)\n",
    "corpus = [dictionary.doc2bow(token) for token in tokens]\n",
    "topic_words = [[words for words, _ in topic_model.get_topic(topic)] \n",
    "               for topic in range(len(set(topics))-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8ac6069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6306890201920521"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate\n",
    "cv_coherence_model = CoherenceModel(topics=topic_words, \n",
    "                                 texts=tokens, \n",
    "                                 corpus=corpus,\n",
    "                                 dictionary=dictionary, \n",
    "                                 coherence='c_v')\n",
    "coherence = cv_coherence_model.get_coherence()\n",
    "coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80b015c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.8477866365429185"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate\n",
    "umass_coherence_model = CoherenceModel(topics=topic_words, \n",
    "                                 texts=tokens, \n",
    "                                 corpus=corpus,\n",
    "                                 dictionary=dictionary, \n",
    "                                 coherence='u_mass')\n",
    "coherence = umass_coherence_model.get_coherence()\n",
    "coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd67c423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.5842301436171595"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate\n",
    "c_uci_coherence_model = CoherenceModel(topics=topic_words, \n",
    "                                 texts=tokens, \n",
    "                                 corpus=corpus,\n",
    "                                 dictionary=dictionary, \n",
    "                                 coherence='c_uci')\n",
    "coherence = c_uci_coherence_model.get_coherence()\n",
    "coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89c401a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07302562870265346"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate\n",
    "c_npmi_coherence_model = CoherenceModel(topics=topic_words, \n",
    "                                 texts=tokens, \n",
    "                                 corpus=corpus,\n",
    "                                 dictionary=dictionary, \n",
    "                                 coherence='c_npmi')\n",
    "coherence = c_npmi_coherence_model.get_coherence()\n",
    "coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ca0933",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9e3cd50",
   "metadata": {},
   "source": [
    "https://github.com/MaartenGr/BERTopic/issues/90\n",
    "\n",
    "https://github.com/MIND-Lab/OCTIS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

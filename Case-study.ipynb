{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10692a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prevent huge warning messages of bertmodel \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "tqdm.pandas()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append('scripts/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc89d3ec",
   "metadata": {},
   "source": [
    "About [preprocessing]( https://github.com/MaartenGr/BERTopic/issues/40), in words of Maarten Grootendorst, author of BERTopic:\n",
    "\n",
    "\n",
    "_\"In general, no, you do not need to preprocess your data. Like you said, keeping the original structure of the text is especially important for transformer-based models to understand the context._\n",
    "\n",
    "_However, there are exceptions to this. For example, if you were to have scraped documents with a lot of html tags, then it might be beneficial to remove those as they do not provide any interesting context.\"_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ee428b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 846.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of news: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from preprocess import filter_by_media\n",
    "from preprocess import cluster_by_month\n",
    "from preprocess import find_cities\n",
    "\n",
    "df = pd.read_csv(\"data/loslagos-comunas.csv\")[:100]\n",
    "df = cluster_by_month(filter_by_media(df))\n",
    "df = df.drop_duplicates(subset='content', keep=\"first\")\n",
    "df.drop(columns=['comuna'], axis=1, inplace=True)\n",
    "df['cities'] =  df.content.progress_apply(lambda x: find_cities(str(x)))\n",
    "docs = df.content.tolist()\n",
    "\n",
    "print(\"number of news:\", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce13cbc",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "### \"Document Clustering\" with [BERTopic](https://github.com/MaartenGr/BERTopic) (+[SentenceTransformer](https://huggingface.co/sentence-transformers/all-mpnet-base-v2) +[Word Embeddings](https://github.com/dccuchile/spanish-word-embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd196dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from bertopic.backend import WordDocEmbedder\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "ft  = KeyedVectors.load_word2vec_format(\"data/SBW-vectors-300-min5.bin.gz\", binary=True) \n",
    "embedding_model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "word_doc_embedder = WordDocEmbedder(embedding_model=embedding_model, word_embedding_model=ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b15ab7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from topic_modeling import model_definition\n",
    "\n",
    "topic_model = model_definition(word_doc_embedder)\n",
    "topic_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422af852",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "topics, probs = topic_model.fit_transform(docs)\n",
    "\n",
    "clusters = topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854385a1",
   "metadata": {},
   "source": [
    "We generate a dataframe with the obtained clusters and extract their most significant tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97442524",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters['most_freq_tokens'] = clusters.Topic.progress_apply(lambda x: topic_model.get_topic(x))\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17509b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clusters.to_csv('data/clusters.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95565ee",
   "metadata": {},
   "source": [
    "We label the news with their clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae5ac05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['topic_name'] = \"\"\n",
    "df['topic_number'] = \"\"\n",
    "\n",
    "# label each row with his topic\n",
    "labels=[]\n",
    "for item in topic_model.generate_topic_labels():\n",
    "    item.partition(\"_\")[2]\n",
    "    labels.append(item)\n",
    "\n",
    "count = 0\n",
    "for doc in tqdm(docs):  \n",
    "    df.at[df.index[df['content'] == doc], 'topic_name'] = labels[topics[count]+1]\n",
    "    df.at[df.index[df['content'] == doc], 'topic_number'] = topics[count]\n",
    "    count+=1\n",
    "    \n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dd0a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('data/labeled_news.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a4ec78",
   "metadata": {},
   "source": [
    "#### Evaluation: Coherence Score\n",
    "\n",
    "There is no one way to determine whether the coherence score is good or bad. The score and its value depends on the data that it's calculated from. For instance, in one case, the score of 0.5 might be good enough but in another case not acceptable. The only rule is that we want to **maximize** the score.\n",
    "\n",
    "Usually, the coherence score will increase with the number of topics . This increase will become smaller as the number of topics get higher. The trade-off between the number of topics and coherence score can be achieved using the so-called elbow technique. The method implies plotting coherence score as a function of number of topics. We use the elbow of the curve to select the number of topics.\n",
    "\n",
    "The idea behind this method is that we want to choose a point after which the diminishing increase of coherence score is no longer worth the additional increase of number of topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1973aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from coherence_eval import umass_npmi\n",
    "\n",
    "umass_coherence, c_npmi_coherence = umass_npmi(docs, topics, topic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b190deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "umass_coherence, c_npmi_coherence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d79b20",
   "metadata": {},
   "source": [
    "#### Hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1685aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster import hierarchy as sch\n",
    "\n",
    "# Hierarchical topics\n",
    "linkage_function = lambda x: sch.linkage(x, 'ward', optimal_ordering=True)\n",
    "hierarchical_topics = topic_model.hierarchical_topics(docs, linkage_function=linkage_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964291f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", 20, 'display.max_colwidth', 50)\n",
    "hierarchical_topics.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e339c50",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig=topic_model.visualize_hierarchy(hierarchical_topics=hierarchical_topics)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49eb112e",
   "metadata": {},
   "source": [
    "#### Topics over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b846585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = df.date.tolist()\n",
    "topics_over_time = topic_model.topics_over_time(docs=docs, \n",
    "                                                timestamps=timestamps, \n",
    "                                                global_tuning=False, \n",
    "                                                evolution_tuning=False, \n",
    "                                                nr_bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837789f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_over_time.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b88e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = topic_model.visualize_topics_over_time(topics_over_time)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0419e1",
   "metadata": {},
   "source": [
    "### 5 _most important_ keywords of documents using [KeyBERT](https://github.com/MaartenGr/KeyBERT) (+[Word Embeddings](https://github.com/dccuchile/spanish-word-embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9d81b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keyword_extraction import extract_ngram_keywords\n",
    "\n",
    "df['2gram_keywords'] = extract_ngram_keywords((2,2), ft, docs)\n",
    "df['3gram_keywords'] = extract_ngram_keywords((3,3), ft, docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c01521",
   "metadata": {},
   "source": [
    "### Sentiment Analysis using [BETO](https://huggingface.co/finiteautomata/beto-sentiment-analysis?text=Te+quiero.+Te+amo.) + Sentiment Analysis/Emotion Analysis using [roBERTuito](https://huggingface.co/pysentimiento/robertuito-sentiment-analysis?text=Te+quiero.+Te+amo.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e1db86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BETO\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "model_name = \"finiteautomata/beto-sentiment-analysis\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "nlp = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ce81b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roBERTuito\n",
    "from pysentimiento import create_analyzer\n",
    "sentiment_analyzer = create_analyzer(task=\"sentiment\", lang=\"es\")\n",
    "emotion_analyzer = create_analyzer(task=\"emotion\", lang=\"es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ce1e0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sentiment_analysis import sentiment_analysis\n",
    "df = sentiment_analysis(df, sentiment_analyzer, nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4794e4",
   "metadata": {},
   "source": [
    "### Manual classification of clusters according to areas of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b1d6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e3817c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "def tokens_to_list(text):\n",
    "    text = text[1:-1]\n",
    "    res = ast.literal_eval(text)\n",
    "    return list(dict(res).keys())\n",
    "\n",
    "\n",
    "clusters = clusters[1:]\n",
    "clusters= clusters.set_index('Name')\n",
    "\n",
    "clusters['tokens'] = clusters.most_freq_tokens.apply(lambda x: str(tokens_to_list(\"{\"+str(x)[1:-1]+\"}\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de8c584",
   "metadata": {},
   "outputs": [],
   "source": [
    "health = clusters[clusters['tokens'].str.contains('salud|cáncer')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b43e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "health_news = pd.DataFrame()\n",
    "for index, rows in health.iterrows():\n",
    "    health_news = pd.concat([health_news, df[df.topic_number == rows['Topic']]])\n",
    "health_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea449618",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
